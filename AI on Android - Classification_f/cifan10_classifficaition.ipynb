{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cifar10 Image Classification with Keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part1. Data preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Cifar10 데이터 가져오기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = ('Airplane', 'car', 'bird', 'cat', 'deer', 'dog', 'forg', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 이미지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROW = 3\n",
    "COLUMN = 3\n",
    "\n",
    "image_indexes = np.random.choice(len(np.array(X_train)), ROW * COLUMN)\n",
    "\n",
    "for i in range(ROW * COLUMN):\n",
    "    label_index = ((y_train[image_indexes][i])[0])\n",
    "    plt.subplot(ROW, COLUMN, 1+i)\n",
    "    plt.imshow(PIL.Image.fromarray(X_train[image_indexes][i]))\n",
    "    plt.title(\"%s\" % class_name[label_index])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 중 일부를 랜덤으로 선택해 이미지와 label 확인\n",
    "ROW = 3\n",
    "COLUMN = 3\n",
    "\n",
    "image_indexes = np.random.choice(len(np.array(X_train)), ROW * COLUMN)\n",
    "\n",
    "for i in range(ROW * COLUMN):\n",
    "    label_index = ((y_train[image_indexes][i])[0])\n",
    "    plt.subplot(ROW, COLUMN, 1+i)\n",
    "    plt.imshow(PIL.Image.fromarray(X_train[image_indexes][i]))\n",
    "    plt.title(\"%s\" % class_name[label_index])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Data 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리: Normalize 0-255 -> 0 ~ 1\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label 전처리\n",
    "import keras.utils as utils\n",
    "\n",
    "y_train = utils.to_categorical(y_train)\n",
    "y_test = utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part2. Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####4. CNN 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D,MaxPooling2D, Activation, Flatten, Dropout\n",
    "from keras import optimizers\n",
    "\n",
    "# 네트워크 쌓기\n",
    "model = Sequential()\n",
    "\n",
    "#Input Layer\n",
    "model.add(Conv2D(8,(3,3), input_shape=(32, 32, 3), padding='same')) # 3x3 필터를 8개 사용할 것\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#hidden Layer\n",
    "model.add(Conv2D(16,(3,3), padding='same')) # 필터는 처음것보단 크게\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) # 모델 축소화, 반반 줄이겠다.\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32,(3,3), padding='same')) # 필터는 유지 또는 크게\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation = 'softmax')) # Dense는 1차원 layer, Dense 안에서 Activation은 소문자 a를 쓴다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "sgd = keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0) #Learning rate, 각운도량, 얼마나 감소할 것인가\n",
    "\n",
    "# Cost Function\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "      # 버전이 달라서 에러가 뜸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # 몇개 보고 확인할지\n",
    "epochs = 30 # 같은 문제 몇 번 볼래? \n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                   epochs=epochs,\n",
    "                   batch_size=batch_size,\n",
    "                   verbose=1,\n",
    "                   validation_data=(X_test, y_test),\n",
    "                   shuffle=True) # 셔플은 next epochs 때 순서를 변화시킴. 이는 순서기억을 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part3. 훈련과정 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가하기\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy : %.2f%%' %(score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part4. Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 랜덤 이미지 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in np.random.choice(len(y_test), 3, replace = False):\n",
    "    predicted = model.predict(X_test[index:index + 1])[0]\n",
    "    label = y_test[index]\n",
    "    result_label = np.where(label == np.amax(label))\n",
    "    result_predicted = np.where(predicted == np.amax(predicted))\n",
    "\n",
    "    title = \"Label value = %d  Predicted value = %d \" % (result_label[0],  result_predicted[0])\n",
    "    fig = plt.figure(1, figsize = (3,3))\n",
    "    ax1 = fig.add_axes((0,0,.8,.8))\n",
    "    ax1.set_title(title)\n",
    "    images = X_test\n",
    "    plt.imshow(images[index], cmap = plt.cm.gray_r, interpolation = 'nearest')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part5. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cifal10_classifier_100epochstest.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.contrib import lite\n",
    "\n",
    "converter = lite.TocoConverter.from_keras_model_file(\"cifal10_classifier_100epochstest.h5\")\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$pip show pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install <tensorflow>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.contrib import lite\n",
    "\n",
    "converter = tf.contrib.lite.TocoConverter.from_keras_model_file(\"cifal10_classifier_100epochstest.h5\")\n",
    "converter.post_training_quantize=True\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install __upgrade tensorflow==1.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.contrib.lite.Interpreter(model_path='cifar10_classifier_test.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
